#!/usr/bin/env python3
"""
镜像文档解析器 - 从Markdown文档生成shell脚本

该程序读取镜像仓库中的markdown文档，解析其中的yaml cli和yaml cli-nodocs代码块，
并根据detection配置生成对应的自动操作换源shell脚本。

支持的yaml cli类型：
- ReplaceIfExist: 替换文件中的匹配内容
- TestAndExecute: 测试条件后执行命令
- Execute: 直接执行命令
"""

import argparse
import logging
import re
import sys
from pathlib import Path
from typing import Any, Dict, List, Tuple

import yaml


class MarkdownParser:
    """Markdown文档解析器"""

    def __init__(self, docs_dir: str = "docs", test: bool = False):
        self.test = test
        self.docs_dir = Path(docs_dir)
        self.gen_tag = "Generated by hust-mirrors auto script"

    def parse_frontmatter(self, content: str) -> Tuple[Dict[str, Any], str]:
        """解析markdown前置元数据"""
        if not content.startswith('---'):
            return {}, content

        parts = content.split('---', 2)
        if len(parts) < 3:
            return {}, content

        try:
            frontmatter = yaml.safe_load(parts[1])
            remaining_content = parts[2]
            return frontmatter or {}, remaining_content
        except yaml.YAMLError:
            return {}, content

    def extract_yaml_cli_blocks(self, content: str) -> List[Dict[str, Any]]:
        """提取yaml cli和yaml cli-nodocs代码块"""
        blocks = []

        # 匹配yaml cli和yaml cli-nodocs代码块
        pattern = r'```yaml cli(?:-nodocs)?\n(.*?)\n```'
        matches = re.findall(pattern, content, re.DOTALL)

        for match in matches:
            try:
                yaml_data = yaml.safe_load(match)
                if yaml_data:
                    blocks.append(yaml_data)
            except yaml.YAMLError as e:
                logging.warning(f"Failed to parse YAML block: {e}")
                if self.test:
                    sys.exit(1)
                continue

        return blocks

    def parse_markdown_file(self, file_path: Path) -> Dict[str, Any]:
        """解析单个markdown文件"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            logging.error(f"Error reading {file_path}: {e}")
            if self.test:
                sys.exit(1)
            return {}

        frontmatter, body_content = self.parse_frontmatter(content)
        yaml_blocks = self.extract_yaml_cli_blocks(body_content)

        return {
            'file_path': file_path,
            'frontmatter': frontmatter,
            'yaml_blocks': yaml_blocks
        }

    def generate_check_function(self, detection: Dict[str, Any], mirror_id: str) -> str:
        """根据detection配置生成check函数"""
        if not detection:
            logging.info(f"No detection rules specified for {mirror_id}")
            return ""

        checks = detection.get('checks', [])
        policy = detection.get('policy', 'AllOf')  # 默认所有条件都要满足

        if not checks:
            logging.warning(f"No checks defined for {mirror_id}")
            if self.test:
                sys.exit(1)
            return ""

        check_lines = []
        check_lines.append("check() {")

        # 如果有os_release类型的检查，先source
        for check in checks:
            if check.get('type') == 'os_release':
                check_lines.append("\tsource_os_release")
                break

        conditions = []
        for check in checks:
            check_type = check.get('type', '')

            if check_type == 'os_release':
                name = check.get('name', '')
                if name:
                    conditions.append(f'[ "$NAME" = "{name}" ]')
                else:
                    logging.warning(f"OS release check missing 'name' for {mirror_id}")
                    if self.test:
                        sys.exit(1)
            elif check_type == 'command':
                command = check.get('command', '')
                if command:
                    conditions.append(f'has_command {command}')
                else:
                    logging.warning(f"Command check missing 'command' for {mirror_id}")
                    if self.test:
                        sys.exit(1) 
            elif check_type == 'file':
                file_path = check.get('path', '')
                if file_path:
                    conditions.append(f'if [ -f {file_path} ]; then\n\treturn 0\nelse\n\treturn 1\nfi')
                else:
                    logging.warning(f"File check missing 'path' for {mirror_id}")
                    if self.test:
                        sys.exit(1)
            else:
                logging.warning(f"Unknown check type: {check_type}")
                if self.test:
                    sys.exit(1)

        if not conditions:
            logging.info(f"No valid conditions found for {mirror_id}")
            check_lines.append("\treturn 1")
            if self.test:
                sys.exit(1)
        elif policy == 'OneOf':
            # 任一条件满足即可
            condition_str = ' || '.join(conditions)
            check_lines.append(f"\t{condition_str}")
        else:
            # 默认AllOf：所有条件都要满足
            condition_str = ' && '.join(conditions)
            check_lines.append(f"\t{condition_str}")

        check_lines.append("}")

        return '\n'.join(check_lines)

    def generate_replace_function(self, yaml_block: Dict[str, Any], func_name: str, mirror_id: str, backed_up_files: set) -> Tuple[str, List[tuple]]:
        """生成ReplaceIfExist类型的函数，返回函数代码和备份文件列表。只对未备份过的文件进行备份。"""
        files = yaml_block.get('files', [])
        privileged = yaml_block.get('privileged', False)
        optional = yaml_block.get('optional', False)
        description = yaml_block.get('description', 'Replace configuration')

        lines = []
        backup_files = []  # 收集备份文件信息 (path, backup_filename)

        lines.append(f"{func_name}() {{")
        lines.append(f"\t# {description}")

        # 如果是可选的，先确认是否执行
        if optional:
            lines.append(f"\tconfirm_y \"是否 {description}?\" || return 0")
            lines.append("")

        if privileged:
            lines.append("\tset_sudo")
            lines.append("")

        for file_config in files:
            path = file_config.get('path', '')
            match_pattern = file_config.get('match', '')
            replace_pattern = file_config.get('replace', '')
            statement = file_config.get('statement', '')
            comment = file_config.get('comment', '')
            flags = file_config.get("flags", "-i -E -e")

            if comment:
                lines.append(f"\t# {comment.lstrip('> ')}")

            # 生成备份文件名（只对第一次出现的文件进行备份）
            backup_filename = f"{mirror_id}_{self._sanitize_filename(path)}.bak"
            do_backup = path not in backed_up_files and path != ''
            if do_backup:
                backup_files.append((path, backup_filename))
                backed_up_files.add(path)

            lines.append(f"\tif [ -f {path} ]; then")
            sudo_prefix = "$sudo " if privileged else ""
            if do_backup:
                lines.append(f"\t\tmkdir -p ${{_backup_dir}} || {{")
                lines.append(f"\t\t\tprint_error \"Failed to create backup directory\"")
                lines.append(f"\t\t\treturn 1")
                lines.append(f"\t\t}}")
                lines.append(f"\t\t[ -f ${{_backup_dir}}/{backup_filename} ] || {sudo_prefix}cp {path} ${{_backup_dir}}/{backup_filename} || {{")
                lines.append(f"\t\t\tprint_error \"Backup {path} failed\"")
                lines.append(f"\t\t\treturn 1")
                lines.append(f"\t\t}}")

            if statement:
                lines.append(f"\t\t{sudo_prefix} sed {flags} \"{statement}\" {path} || {{")
            else:
                # 执行替换

                if len(replace_pattern) == 0 or len(match_pattern) == 0:
                    logging.error(f"Empty pattern for {mirror_id}")
                    if self.test:
                        sys.exit(1)

                replace_processed = replace_pattern.replace('${_http}', '$http').replace('${_domain}', '$domain')
                match_processed = match_pattern.replace('${_http}', '$http').replace('${_domain}', '$domain')
                replace_escaped = replace_processed.replace(r'\/', r'/')
                match_escaped = match_processed.replace(r'\/', r'/')
                lines.append(f"\t\t{sudo_prefix}sed -i -E -e \"s|{match_escaped}|{replace_escaped}|g\" {path} || {{")

            lines.append(f"\t\t\tprint_error \"Failed to update {path}\"")
            lines.append(f"\t\t\treturn 1")
            lines.append(f"\t\t}}")
            lines.append(f"\telse")
            lines.append(f"\t\tprint_warning \"File {path} does not exist\"")
            lines.append(f"\tfi")
            lines.append("")

        lines.append("\treturn 0")
        lines.append("}")

        return '\n'.join(lines), backup_files

    def _sanitize_filename(self, path: str) -> str:
        """将路径转换为安全的文件名（去除/等特殊字符）"""
        return re.sub(r'[^A-Za-z0-9_.-]', '_', path)

    def generate_test_execute_function(self, yaml_block: Dict[str, Any], func_name: str, mirror_id: str) -> Tuple[str, str]:
        """生成TestAndExecute类型的函数，返回函数代码和恢复命令"""
        test_script = yaml_block.get('test', '').strip()
        exec_script = yaml_block.get('exec', '').strip()
        recover_script = yaml_block.get('recover', '').strip()
        privileged = yaml_block.get('privileged', False)
        required = yaml_block.get('required', False)
        optional = yaml_block.get('optional', False)
        provide_backup = yaml_block.get('provide_backup', False)
        description = yaml_block.get('description', 'Test and execute' if test_script else 'Execute commands')

        lines = []
        lines.append(f"{func_name}() {{")
        lines.append(f"\t# {description}")

        # 如果是可选的，先确认是否执行
        if optional:
            lines.append(f"\tconfirm_y \"{description}?\" || return 0")
            lines.append("")

        if privileged:
            lines.append("\tset_sudo")
            lines.append("")

        # 如果需要备份路径，设置备份文件变量
        if provide_backup:
            lines.append(f"\tbackup_path=\"${{_backup_dir}}\"")
            lines.append("")

        # 添加测试部分
        if test_script:
            lines.append("\t# Test conditions")
            for line in test_script.split('\n'):
                line = line.strip()
                if line:
                    # 转义引号以避免shell语法错误
                    line_escaped = line.replace('"', '\\"')
                    lines.append(f"\t{line} || {{")
                    lines.append(f"\t\tprint_warning \"Test condition failed: {line_escaped}\"")
                    if required:
                        lines.append(f"\t\treturn 1")
                    lines.append(f"\t}}")
            lines.append("")

        # 添加执行部分
        if exec_script:
            lines.append("\t# Execute commands")
            # 处理备份路径替换
            if provide_backup:
                exec_script = exec_script.replace('${_backup_dir}', '$backup_path')

            # 处理文档标记 #{USE_IN_DOCS/} 和 #{/USE_IN_DOCS}
            # 这些标记内的内容应该被保留，而标记本身应该被移除
            exec_script = re.sub(r'#\{USE_IN_DOCS/\}\s*\n?', '', exec_script)
            exec_script = re.sub(r'\s*#\{/USE_IN_DOCS\}', '', exec_script)

            if len(exec_script) == 0:
                logging.error(f"Empty exec script for {mirror_id}")
                if self.test:
                    sys.exit(1)

            # 处理变量替换
            exec_script = exec_script.replace('${_domain}', '$domain').replace('${_http}', '$http')

            sudo_prefix = "$sudo " if privileged else ""
            in_heredoc = False
            heredoc_delimiter = None

            for line in exec_script.split('\n'):
                original_line = line
                line = line.strip()

                if not line:
                    continue

                # 检测here-document开始
                if '<<' in line and not in_heredoc:
                    # 查找分隔符
                    parts = line.split('<<', 1)
                    if len(parts) == 2:
                        delimiter_part = parts[1].strip()
                        if delimiter_part:
                            heredoc_delimiter = delimiter_part.split()[0]
                            in_heredoc = True
                            if line.startswith('mkdir') or line.startswith('cp') or line.startswith('mv') or line.startswith('tee') or line.startswith('touch'):
                                lines.append(f"\t{sudo_prefix}{line}")
                            else:
                                lines.append(f"\t{line}")
                            continue

                # 检测here-document结束
                if in_heredoc and line == heredoc_delimiter:
                    lines.append(line)  # EOF不加制表符前缀
                    in_heredoc = False
                    heredoc_delimiter = None
                    continue

                # here-document内容
                if in_heredoc:
                    lines.append(original_line)  # 保持原始缩进
                    continue

                # shell控制结构
                if line.startswith('if') or line.startswith('else') or line.startswith('fi') or line.startswith('while') or line.startswith('do') or line.startswith('done') or line.startswith('for'):
                    lines.append(f"\t{line}")
                else:
                    # 普通命令
                    lines.append(f"\t{sudo_prefix}{line}")

        lines.append("")
        lines.append("\treturn 0")
        lines.append("}")

        # 处理恢复脚本
        processed_recover = ""
        if recover_script:
            # 处理变量替换
            processed_recover = recover_script.replace('${_backup_dir}', '$_backup_dir').replace('${_domain}', '$domain').replace('${_http}', '$http')

        return '\n'.join(lines), processed_recover


    def collect_backup_files(self, yaml_blocks: List[Dict[str, Any]], mirror_id: str) -> List[str]:
        """收集所有会在${_backup_dir}中创建的文件名"""
        backup_files = []

        for i, yaml_block in enumerate(yaml_blocks):
            block_type = yaml_block.get('type', '')

            if block_type == 'ReplaceIfExist':
                # ReplaceIfExist操作会为每个文件创建备份
                files = yaml_block.get('files', [])
                for file_idx, file_config in enumerate(files):
                    backup_filename = f"{mirror_id}_{i+1}_{file_idx+1}.bak"
                    backup_files.append(backup_filename)

            elif block_type in ['TestAndExecute', 'Execute']:
                # 检查exec脚本中是否有写入${_backup_dir}的操作
                exec_script = yaml_block.get('exec', '')
                if exec_script and '${_backup_dir}' in exec_script:
                    # 分析脚本中可能创建的文件
                    lines = exec_script.split('\n')
                    for line in lines:
                        line = line.strip()
                        if '${_backup_dir}' in line:
                            # 尝试提取文件名模式
                            # 例如: "config get global.index-url > ${_backup_dir}/pip.bak"

                            redirect_match = re.search(r'>\s*\$\{_backup_dir\}/([^\s]+)', line)
                            if redirect_match:
                                backup_files.append(redirect_match.group(1))
                            cp_match = re.search(r'cp\s+[^>]*?\s+\$\{_backup_dir\}/([^\s]+)', line)
                            if cp_match:
                                backup_files.append(cp_match.group(1))
                            mv_match = re.search(r'mv\s+[^>]*?\s+\$\{_backup_dir\}/([^\s]+)', line)
                            if mv_match:
                                backup_files.append(mv_match.group(1))

        return backup_files

    def generate_shell_script(self, parsed_data: Dict[str, Any]) -> str:
        """生成完整的shell脚本"""
        frontmatter = parsed_data['frontmatter']
        yaml_blocks = parsed_data['yaml_blocks']

        mirror_id = frontmatter.get('id')
        if not mirror_id:
            # 从sidebar_label或文件名推断ID
            mirror_label = frontmatter.get('sidebar_label', '')
            if mirror_label:
                mirror_id = mirror_label.lower().replace(' ', '-')
            else:
                mirror_id = parsed_data['file_path'].stem

        mirror_label = frontmatter.get('sidebar_label', mirror_id)
        detection = frontmatter.get('detection', {})

        script_lines = []
        script_lines.append(f"# Auto-generated script for {mirror_label}")
        script_lines.append(f"# Generated from: {parsed_data['file_path'].name}")
        script_lines.append(f"# Mirror ID: {mirror_id}")
        script_lines.append(f"")

        # 生成check函数
        check_function = self.generate_check_function(detection, mirror_id)
        script_lines.append(check_function)
        script_lines.append("")

        # 收集恢复命令和备份文件
        recover_commands = []
        backup_files = []
        backed_up_files = set()  # 跟踪已备份的文件路径

        # 为每个yaml block生成函数
        install_functions = []
        for i, yaml_block in enumerate(yaml_blocks):
            block_type = yaml_block.get('type', '')
            func_name = f"_{mirror_id.replace('-', '_').replace('.', '_')}_install_{i+1}"

            if block_type == 'ReplaceIfExist':
                func_code, backup_info = self.generate_replace_function(yaml_block, func_name, mirror_id, backed_up_files)
                script_lines.append(func_code)
                script_lines.append("")
                install_functions.append(func_name)
                backup_files.extend(backup_info)
            elif block_type == 'TestAndExecute' or block_type == 'Execute':
                func_code, recover_cmd = self.generate_test_execute_function(yaml_block, func_name, mirror_id)
                script_lines.append(func_code)
                script_lines.append("")
                install_functions.append(func_name)
                if recover_cmd:
                    recover_commands.append(recover_cmd)
            else:
                logging.warning(f"Unknown yaml block type: {block_type}")

        # 生成主install函数
        if install_functions:
            script_lines.append("install() {")
            script_lines.append("")
            for func_name in install_functions:
                script_lines.append(f"\t{func_name} || return 1")
            script_lines.append("\tprint_success \"Mirror configuration updated successfully\"")
            script_lines.append("}")
            script_lines.append("")
        elif self.test:
            logging.error(f"No install functions generated for {mirror_id}")
            sys.exit(1)

        # 生成recover函数
        script_lines.append("uninstall() {")
        script_lines.append("\t# Recover from backup files and execute recovery commands")
        script_lines.append("\tprint_info \"Starting recovery process...\"")
        script_lines.append("")

        # 添加ReplaceIfExist的自动恢复
        if backup_files:
            script_lines.append("\t# Restore files from backup")
            for original_path, backup_filename in backup_files:
                script_lines.append(f"\tif [ -f ${{_backup_dir}}/{backup_filename} ]; then")
                script_lines.append(f"\t\tset_sudo")
                script_lines.append(f"\t\tcp \"${{_backup_dir}}/{backup_filename}\" {original_path} 2>/dev/null || true")
                script_lines.append(f"\t\tprint_info \"Restored {original_path}\"")
                script_lines.append(f"\tfi")

        # 添加recover命令
        if recover_commands:
            script_lines.append("")
            script_lines.append("\t# Execute recovery commands")
            for recover_cmd in recover_commands:
                if recover_cmd.strip():
                    for line in recover_cmd.split('\n'):
                        if line.strip():
                            script_lines.append(f"\t{line.strip()} 2>/dev/null || true")

        script_lines.append("")
        script_lines.append("\tprint_success \"Recovery completed\"")
        script_lines.append("}")
        script_lines.append("")

        # 只有当存在ReplaceIfExist操作时才生成相应函数
        has_replace_operations = any(yaml_block.get('type') == 'ReplaceIfExist' for yaml_block in yaml_blocks)

        if has_replace_operations:
            # 生成can_recover函数 - 检查实际生成的备份文件是否存在
            script_lines.append("can_recover() {")
            script_lines.append("\t# Check if any backup files exist")
            if backup_files:
                conditions = []
                for _, backup_filename in backup_files:
                    conditions.append(f"[ -f ${{_backup_dir}}/{backup_filename} ]")
                condition_str = " || ".join(conditions)
                script_lines.append(f"\t{condition_str}")
            else:
                script_lines.append("\t[ -d $_backup_dir ] && [ -n $(ls -A $_backup_dir 2>/dev/null) ]")
            script_lines.append("}")
            script_lines.append("")

            # 生成is_deployed函数 - 检查替换的文件中是否包含域名变量
            if backup_files:
                script_lines.append("is_deployed() {")
                script_lines.append("\t# Check if any replaced file contains domain variable")
                # 去重文件路径
                unique_paths = set(original_path for original_path, _ in backup_files)
                for original_path in unique_paths:
                    script_lines.append(f"\t[ -f {original_path} ] && grep -q \"$domain\" {original_path} 2>/dev/null && return 0")
                script_lines.append("\treturn 1")
                script_lines.append("}")
                script_lines.append("")

        return '\n'.join(script_lines)

    def process_all_docs(self, output_dir: str = "generated_scripts") -> None:
        """处理所有文档并生成脚本"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        if not self.docs_dir.exists():
            logging.error(f"Error: Documentation directory {self.docs_dir} does not exist")
            if self.test:
                sys.exit(1)
            return

        processed_count = 0

        for md_file in self.docs_dir.glob("*.md"):
            parsed_data = self.parse_markdown_file(md_file)

            if not parsed_data.get('yaml_blocks'):
                logging.warning(f"Skipping {md_file.name}: No yaml cli blocks found")
                continue

            mirror_id = parsed_data['frontmatter'].get('id')
            if not mirror_id:
                mirror_id = md_file.stem

            script_content = self.generate_shell_script(parsed_data)

            output_file = output_path / f"{mirror_id}.sh"
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(script_content)
                logging.info(f"Generated: {output_file}")
                processed_count += 1
            except Exception as e:
                logging.error(f"Error writing {output_file}: {e}")

        logging.info(f"\nProcessed {processed_count} documentation files")


def main():
    """主函数"""
    parser = argparse.ArgumentParser(
        description="Generate shell scripts from mirror documentation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        'docs_dir',
        nargs='?',
        default='docs',
        help='Directory containing markdown documentation files (default: docs)'
    )
    
    parser.add_argument(
        '-o', '--output',
        default='generated_scripts',
        help='Output directory for generated scripts (default: generated_scripts)'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose output'
    )

    parser.add_argument(
        '-t', '--test',
        action='store_true',
        help='Return error if warning or error occurs during script generation'
    )
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        logging.info(f"Parsing documentation from: {args.docs_dir}")
        logging.info(f"Output directory: {args.output}")

    try:
        markdown_parser = MarkdownParser(args.docs_dir, args.test)
        markdown_parser.process_all_docs(args.output)
    except KeyboardInterrupt:
        logging.info("\nOperation cancelled by user")
        sys.exit(1)
    except Exception as e:
        logging.error(f"Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
